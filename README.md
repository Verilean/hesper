# Hesper

**Write GPU programs in Lean 4. Prove them correct. Run on WebGPU.**

Hesper is a verified GPU programming framework that brings the power of formal verification to GPU computing. Write type-safe shaders, execute tensor operations, and build graphics applicationsâ€”all in Lean 4.

```lean
import Hesper.WGSL.DSL

-- Type-safe shader expressions with compile-time verification
let x : Exp (.scalar .f32) := var "x"
let y : Exp (.scalar .f32) := var "y"
let result := sqrt (x * x + y * y)  -- Generates: sqrt(x * x + y * y)

-- Cannot mix types (compile error!)
-- let wrong := x + (var "i" : Exp (.scalar .i32))  âœ— Type error!
```

## Why Hesper?

Modern GPU programming lacks safety guarantees. Hesper provides:

- **Type Safety**: Shaders are type-checked at compile time, preventing type mismatches
- **Formal Verification**: Prove correctness properties about your GPU programs
- **WebGPU Backend**: Cross-platform GPU access via Dawn (Metal, Vulkan, D3D12)
- **Lean Integration**: Use Lean's powerful theorem proving alongside GPU computation
- **Multi-GPU Support**: Select and coordinate across multiple GPU adapters

## Quick Start

### Prerequisites

- **Lean 4** (latest version recommended)
- **CMake** 3.16+
- **C++17** compiler (Clang/GCC)
- **Platform**: macOS (Metal), Linux (Vulkan), or Windows (D3D12/Vulkan)

### Installation

```bash
# Clone the repository
git clone https://github.com/Verilean/hesper.git
cd hesper

# Build native dependencies (this will take a while on first build)
lake run buildNative

# Build and run a demo
lake build dsl-basics
./.lake/build/bin/dsl-basics
```

### Your First Hesper Program

Create `MyFirst.lean`:

```lean
import Hesper
import Hesper.WebGPU.Device

def main : IO Unit := do
  -- Initialize WebGPU
  Hesper.init

  -- Get a GPU device
  let device â† Hesper.WebGPU.getDevice

  IO.println "âœ“ GPU ready!"
```

Build and run:

```bash
lake build myfirst
./.lake/build/bin/myfirst
```

## Features

### ğŸ¯ Type-Safe Shader DSL

Write WGSL shaders with Lean's type system guaranteeing correctness:

```lean
import Hesper.WGSL.DSL

-- Expressions are typed and checked at compile time
let x : Exp (.scalar .f32) := var "x"
let y : Exp (.scalar .f32) := var "y"

-- Arithmetic operators work naturally
let distance := sqrt (x * x + y * y)

-- Built-in functions
let clamped := Exp.clamp x (lit 0.0) (lit 1.0)
let power := Exp.pow x (lit 2.0)

-- Generate WGSL code
IO.println distance.toWGSL  -- Output: sqrt((x * x) + (y * y))
```

### âš™ï¸ GPU Computation

Execute compute shaders and tensor operations on the GPU:

```lean
import Hesper.Compute

-- Matrix multiplication on GPU
let A : Matrix 1024 1024 := ...
let B : Matrix 1024 1024 := ...

-- Runs on GPU automatically
let C â† matmul A B

-- Neural network layers with automatic differentiation
let conv â† Conv2D.create inputChannels outputChannels kernelSize
let output â† conv.forward input
```

### ğŸ® Graphics & Windowing

Build interactive graphics applications with GLFW integration:

```lean
import Hesper.GLFW

def main : IO Unit := do
  Hesper.init

  withGLFW do
    let window â† createWindow 800 600 "Hesper Graphics"
    let device â† Hesper.WebGPU.getDevice
    let surface â† createSurface device window

    -- Render loop
    gameLoop window surface
```

### ğŸ”Œ Multi-GPU Support

Enumerate and select GPUs in multi-GPU systems:

```lean
import Hesper.WebGPU.Device

-- List all available GPUs
Hesper.WebGPU.listAdapters

-- Select specific GPU
let device0 â† getDeviceByIndex 0  -- First GPU
let device1 â† getDeviceByIndex 1  -- Second GPU

-- Get adapter information
let info â† getAdapterInfo 0
IO.println s!"GPU: {info.name} (Backend: {info.backendType})"
```

## Examples

### WebGPU Tetris

A full Tetris implementation using GLFW and WebGPU, demonstrating:
- Dynamic shader generation
- Real-time rendering
- Input handling
- Game state management

```bash
lake build tetris
./.lake/build/bin/tetris
```

**Controls**: A/D (move), S (drop), Space (rotate), ESC (exit)

### Matrix Multiplication

High-performance matrix multiplication with subgroup optimizations:

```bash
lake build matmul-demo
./.lake/build/bin/matmul-demo
```

Demonstrates:
- GPU buffer management
- Compute shader execution
- Performance profiling
- Result verification

### Multi-GPU Demo

Enumerate GPUs and create devices from specific adapters:

```bash
lake build multigpu
./.lake/build/bin/multigpu
```

Output:
```
Found 2 GPU adapter(s):
  [0] NVIDIA GeForce RTX 3080 (Backend: Vulkan)
  [1] Intel UHD Graphics 630 (Backend: Vulkan)
âœ“ Device created from GPU 0
```

### Neural Network Training

Automatic differentiation and gradient descent on GPU:

```bash
lake build nn-gpu-demo
./.lake/build/bin/nn-gpu-demo
```

Features:
- Conv2D layers with verified gradients
- Backpropagation on GPU
- Real-time training visualization

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Lean 4 Code                               â”‚
â”‚  â€¢ Type-safe shader DSL                                      â”‚
â”‚  â€¢ Tensor operations                                         â”‚
â”‚  â€¢ Formal proofs                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              WGSL Code Generation                            â”‚
â”‚  Exp (.scalar .f32) â†’ WGSL shader source                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Lean FFI (C++ Bridge)                           â”‚
â”‚  â€¢ lean_hesper_* functions                                   â”‚
â”‚  â€¢ Resource management via Lean.External                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Google Dawn (WebGPU Native)                     â”‚
â”‚  â€¢ Metal (macOS)                                             â”‚
â”‚  â€¢ Vulkan (Linux/Windows)                                    â”‚
â”‚  â€¢ D3D12 (Windows)                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture Layers

1. **DSL Layer**: Type-safe WGSL expression builder with dependent types
2. **Tensor Layer**: High-level operations (matmul, conv2d, pooling)
3. **Compute Layer**: Shader compilation, buffer management, execution
4. **WebGPU Layer**: FFI bindings to Dawn native implementation
5. **Backend Layer**: Platform-specific GPU drivers (Metal/Vulkan/D3D12)

## Project Structure

```
Hesper/
â”œâ”€â”€ Hesper/
â”‚   â”œâ”€â”€ WGSL/          # Type-safe shader DSL
â”‚   â”‚   â”œâ”€â”€ Types.lean      # WGSL type system
â”‚   â”‚   â”œâ”€â”€ Exp.lean        # Expression AST
â”‚   â”‚   â””â”€â”€ DSL.lean        # User-facing DSL
â”‚   â”œâ”€â”€ WebGPU/        # WebGPU bindings
â”‚   â”‚   â”œâ”€â”€ Device.lean     # GPU device management
â”‚   â”‚   â”œâ”€â”€ Buffer.lean     # GPU buffers
â”‚   â”‚   â”œâ”€â”€ Shader.lean     # Shader modules
â”‚   â”‚   â””â”€â”€ Pipeline.lean   # Compute/render pipelines
â”‚   â”œâ”€â”€ Tensor/        # Tensor operations
â”‚   â”‚   â””â”€â”€ MatMul.lean     # Matrix multiplication
â”‚   â”œâ”€â”€ NN/            # Neural network layers
â”‚   â”‚   â””â”€â”€ Conv.lean       # Convolution layers
â”‚   â”œâ”€â”€ GLFW/          # Windowing and graphics
â”‚   â”‚   â””â”€â”€ GLFW.lean       # GLFW bindings
â”‚   â””â”€â”€ Compute.lean   # High-level compute API
â”œâ”€â”€ Examples/          # Example programs
â”‚   â”œâ”€â”€ Tetris.lean         # Full game demo
â”‚   â”œâ”€â”€ MultiGPU.lean       # Multi-GPU support
â”‚   â”œâ”€â”€ DSLBasics.lean      # DSL tutorial
â”‚   â””â”€â”€ ...
â”œâ”€â”€ native/            # C++ WebGPU bridge
â”‚   â”œâ”€â”€ bridge.cpp          # FFI implementation
â”‚   â””â”€â”€ CMakeLists.txt      # Build configuration
â””â”€â”€ lakefile.lean      # Lake build script
```

## Roadmap

**Current Status**: Early Development (Alpha)

Completed:
- [x] WebGPU device initialization via Dawn
- [x] Type-safe WGSL DSL
- [x] Compute shader execution
- [x] Buffer management (GPU â†” CPU)
- [x] GLFW windowing integration
- [x] Multi-GPU adapter enumeration
- [x] Basic matrix operations
- [x] Convolution layers
- [x] Automatic differentiation

In Progress:
- [ ] Comprehensive tensor operation library
- [ ] Neural network training framework
- [ ] Performance optimization (subgroup operations)
- [ ] Verification of GPU kernel correctness

Future:
- [ ] Formal proofs of numerical stability
- [ ] Compiler optimizations for shader generation
- [ ] Distributed multi-GPU training
- [ ] Integration with Lean's tactic framework
- [ ] Ray tracing support

## Contributing

Hesper is part of the **Verilean** organization's effort to bring verified computing to GPUs.

- **Report Issues**: [GitHub Issues](https://github.com/Verilean/hesper/issues)
- **Discussions**: [GitHub Discussions](https://github.com/Verilean/hesper/discussions)
- **Sister Project**: [Sparkle HDL](https://github.com/Verilean/sparkle) - Verified hardware design in Lean 4

## Author

**Junji Hashimoto**

Twitter/X: [@junjihashimoto3](https://twitter.com/junjihashimoto3)

## License

Apache License 2.0 - see LICENSE file for details

## Acknowledgments

- **Google Dawn** for the WebGPU native implementation
- **Lean 4** for the foundation of verified programming
- **WebGPU Working Group** for the standard
- **Verilean Community** for support and contributions

---

*Write GPU code that's not just fastâ€”make it correct by construction.*
